{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5ad14bf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "35254092",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>author</th>\n",
       "      <th>content</th>\n",
       "      <th>is_retweet</th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>following</th>\n",
       "      <th>followers</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Shallon Enlow</td>\n",
       "      <td>Thanks, Chairman @rssharma3! Enjoyed getting t...</td>\n",
       "      <td>False</td>\n",
       "      <td>8.250000e+17</td>\n",
       "      <td>428</td>\n",
       "      <td>721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Shallon Enlow</td>\n",
       "      <td>\"When they go low, we go high.\" RT @ubergeekse...</td>\n",
       "      <td>False</td>\n",
       "      <td>8.250000e+17</td>\n",
       "      <td>428</td>\n",
       "      <td>721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Shallon Enlow</td>\n",
       "      <td>RT @Camaran: Thanks for that, Chairman @AjitPa...</td>\n",
       "      <td>True</td>\n",
       "      <td>8.250000e+17</td>\n",
       "      <td>428</td>\n",
       "      <td>721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Shallon Enlow</td>\n",
       "      <td>If you haven't heard @hankhunt2's powerful sto...</td>\n",
       "      <td>False</td>\n",
       "      <td>8.250000e+17</td>\n",
       "      <td>428</td>\n",
       "      <td>721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Shallon Enlow</td>\n",
       "      <td>Especially grateful for unanimous passage of #...</td>\n",
       "      <td>False</td>\n",
       "      <td>8.250000e+17</td>\n",
       "      <td>428</td>\n",
       "      <td>721</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0         author  \\\n",
       "0           0  Shallon Enlow   \n",
       "1           1  Shallon Enlow   \n",
       "2           2  Shallon Enlow   \n",
       "3           3  Shallon Enlow   \n",
       "4           4  Shallon Enlow   \n",
       "\n",
       "                                             content  is_retweet  \\\n",
       "0  Thanks, Chairman @rssharma3! Enjoyed getting t...       False   \n",
       "1  \"When they go low, we go high.\" RT @ubergeekse...       False   \n",
       "2  RT @Camaran: Thanks for that, Chairman @AjitPa...        True   \n",
       "3  If you haven't heard @hankhunt2's powerful sto...       False   \n",
       "4  Especially grateful for unanimous passage of #...       False   \n",
       "\n",
       "       tweet_id following followers  \n",
       "0  8.250000e+17       428       721  \n",
       "1  8.250000e+17       428       721  \n",
       "2  8.250000e+17       428       721  \n",
       "3  8.250000e+17       428       721  \n",
       "4  8.250000e+17       428       721  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_deleted = pd.read_csv(\"data_deleted.csv\",low_memory=False)\n",
    "data_deleted.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "52de73d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "legitmate_data = pd.read_csv(\"3000_legitimate_data.csv\",low_memory=False)\n",
    "new_data_deleted = pd.read_csv(\"3000_deleted_data.csv\",low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b788a021",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = [isinstance(item, (str, bytes)) for item in new_data_deleted['Content']]\n",
    "new_data_deleted= new_data_deleted.loc[mask]\n",
    "\n",
    "mask_2 = [isinstance(item, (str, bytes)) for item in legitmate_data['Content']]\n",
    "legitmate_data = legitmate_data.loc[mask_2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a7935d26",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "stop_words = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "feedb3e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unigram and bigram\n",
    "# load in all the modules we're going to need\n",
    "import nltk, re, string, collections\n",
    "from nltk.util import ngrams # function for making ngrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "887deef5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Preprocessing \n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "from nltk.tokenize import WordPunctTokenizer\n",
    "tok = WordPunctTokenizer()\n",
    "pat1 = r'@[A-Za-z0-9]+'\n",
    "pat2 = r'https?://[A-Za-z0-9./]+'\n",
    "combined_pat = r'|'.join((pat1, pat2))\n",
    "\n",
    "def tweet_cleaner(text):\n",
    "    soup = BeautifulSoup(text, 'html.parser')\n",
    "    #soup = BeautifulSoup(s,  \"html.parser\")\n",
    "    souped = soup.get_text()\n",
    "    stripped = re.sub(combined_pat, '', souped)\n",
    "    try:\n",
    "        clean = stripped.decode(\"utf-8-sig\").replace(u\"\\ufffd\", \"?\")\n",
    "    except:\n",
    "        clean = stripped\n",
    "    letters_only = re.sub(\"[^a-zA-Z]\", \" \", clean)\n",
    "    lower_case = letters_only.lower()\n",
    "    \n",
    "    # During the letters_only process two lines above, it has created unnecessay white spaces,\n",
    "    # I will tokenize and join together to remove unneccessary white spaces\n",
    "    \n",
    "    words = tok.tokenize(lower_case)\n",
    "    return (\" \".join(words)).strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d5e1bb62",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Maryam\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\bs4\\__init__.py:435: MarkupResemblesLocatorWarning: The input looks more like a filename than markup. You may want to open this file and pass the filehandle into Beautiful Soup.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Maryam\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\bs4\\__init__.py:404: MarkupResemblesLocatorWarning: The input looks more like a URL than markup. You may want to use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "new_data_deleted['Clean'] = new_data_deleted.apply(lambda row: tweet_cleaner(row['Content']), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6aca940b",
   "metadata": {},
   "outputs": [],
   "source": [
    "legitmate_data['Clean'] = legitmate_data.apply(lambda row: tweet_cleaner(row['Content']), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2bac9e32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('rnc', 'NN'), ('chair', 'NN'), ('cspan', 'VBP'), ('around', 'IN'), ('pm', 'NN'), ('tonight', 'NN'), ('cpac', 'NN')]\n"
     ]
    }
   ],
   "source": [
    "tokenized = sent_tokenize(new_data_deleted['Clean'][0])    \n",
    "for i in tokenized:\n",
    "     \n",
    "    # Word tokenizers is used to find the words\n",
    "    # and punctuation in a string\n",
    "    wordsList = nltk.word_tokenize(i)\n",
    "    # removing stop words from wordList\n",
    "    wordsList = [w for w in wordsList if not w in stop_words]\n",
    " \n",
    "    #  Using a Tagger. Which is part-of-speech\n",
    "    # tagger or POS-tagger.\n",
    "    tagged = nltk.pos_tag(wordsList)\n",
    "    print(tagged)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "dbf7d2b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def post_tags(row):\n",
    "    tokenized = sent_tokenize(row)\n",
    "    my_list = []\n",
    "    \n",
    "    for i in tokenized:\n",
    "     \n",
    "        # Word tokenizers is used to find the words\n",
    "        # and punctuation in a string\n",
    "        wordsList = nltk.word_tokenize(i)\n",
    "        # removing stop words from wordList\n",
    "        wordsList = [w for w in wordsList if not w in stop_words]\n",
    " \n",
    "        #  Using a Tagger. Which is part-of-speech\n",
    "        # tagger or POS-tagger.\n",
    "        tagged = nltk.pos_tag(wordsList)\n",
    "        \n",
    "        for  word in tagged:\n",
    "            my_list.append(word[1])\n",
    "        #my_list.append((tagged))\n",
    "    return(my_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fdf637b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data_deleted['Postags'] = new_data_deleted.apply(lambda row: post_tags(row['Clean']), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "838fd116",
   "metadata": {},
   "outputs": [],
   "source": [
    "legitmate_data['Postags'] = legitmate_data.apply(lambda row: post_tags(row['Clean']), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "13cecf24",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.data import load\n",
    "tagdict = load('help/tagsets/upenn_tagset.pickle')\n",
    "#tagdict['#']='HASH'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d53cd9eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in tagdict.keys():\n",
    "    new_data_deleted[i]=np.zeros(3000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ab82ca24",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in tagdict.keys():\n",
    "    legitmate_data[i]=np.zeros(3000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "3100465f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Maryam\\AppData\\Local\\Temp/ipykernel_5124/3909286485.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  new_data_deleted[i][j]=new_data_deleted[i][j]+1\n"
     ]
    }
   ],
   "source": [
    "for j in range(len(new_data_deleted)):\n",
    "    for i in new_data_deleted['Postags'][j]:\n",
    "        new_data_deleted[i][j]=new_data_deleted[i][j]+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "63b9440e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Maryam\\AppData\\Local\\Temp/ipykernel_5124/2319622087.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  legitmate_data[i][j]=legitmate_data[i][j]+1\n"
     ]
    }
   ],
   "source": [
    "for j in range(len(legitmate_data)):\n",
    "    for i in legitmate_data['Postags'][j]:\n",
    "        legitmate_data[i][j]=legitmate_data[i][j]+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ecac19fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(new_data_deleted)):\n",
    "     new_data_deleted.iloc[i, 8:55]=new_data_deleted.iloc[i, 8:55]/len(new_data_deleted['Postags'][i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "1497961b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(legitmate_data)):\n",
    "     legitmate_data.iloc[i, 8:55]=legitmate_data.iloc[i, 8:55]/len(legitmate_data['Postags'][i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "237e8f68",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Freq_Unigram(row):\n",
    "    Unigram= row.split()\n",
    "    #freq = nltk.FreqDist(Unigram)\n",
    "    return (Unigram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "9828f8c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Freq_Bigram(row):\n",
    "    tokens = nltk.word_tokenize(row)\n",
    "    Bigram= list(nltk.ngrams(tokens,2))\n",
    "    #freq = nltk.FreqDist(Bigram)\n",
    "    return(Bigram)\n",
    "#     my_list=[]\n",
    "#     for i in freq.values():\n",
    "#         f=i/len(freq)\n",
    "#         my_list.append(f)\n",
    "#     return my_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "5790be10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Author</th>\n",
       "      <th>Content</th>\n",
       "      <th>Tweet_id</th>\n",
       "      <th>Following</th>\n",
       "      <th>Followers</th>\n",
       "      <th>Deleted</th>\n",
       "      <th>Clean</th>\n",
       "      <th>Postags</th>\n",
       "      <th>LS</th>\n",
       "      <th>TO</th>\n",
       "      <th>...</th>\n",
       "      <th>WRB</th>\n",
       "      <th>NNP</th>\n",
       "      <th>EX</th>\n",
       "      <th>NNS</th>\n",
       "      <th>SYM</th>\n",
       "      <th>CC</th>\n",
       "      <th>CD</th>\n",
       "      <th>POS</th>\n",
       "      <th>Freq_unigram</th>\n",
       "      <th>Freq_bigram</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sean Spicer</td>\n",
       "      <td>RNC Chair @rnc @ReincePriebus will be on CSPAN...</td>\n",
       "      <td>1.680000e+17</td>\n",
       "      <td>995</td>\n",
       "      <td>448K</td>\n",
       "      <td>1</td>\n",
       "      <td>rnc chair will be on cspan around pm tonight f...</td>\n",
       "      <td>[NN, NN, VBP, IN, NN, NN, NN]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[rnc, chair, will, be, on, cspan, around, pm, ...</td>\n",
       "      <td>[(rnc, chair), (chair, will), (will, be), (be,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 55 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Author                                            Content  \\\n",
       "0  Sean Spicer  RNC Chair @rnc @ReincePriebus will be on CSPAN...   \n",
       "\n",
       "       Tweet_id Following Followers  Deleted  \\\n",
       "0  1.680000e+17       995      448K        1   \n",
       "\n",
       "                                               Clean  \\\n",
       "0  rnc chair will be on cspan around pm tonight f...   \n",
       "\n",
       "                         Postags   LS   TO  ...  WRB  NNP   EX  NNS  SYM   CC  \\\n",
       "0  [NN, NN, VBP, IN, NN, NN, NN]  0.0  0.0  ...  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "\n",
       "    CD  POS                                       Freq_unigram  \\\n",
       "0  0.0  0.0  [rnc, chair, will, be, on, cspan, around, pm, ...   \n",
       "\n",
       "                                         Freq_bigram  \n",
       "0  [(rnc, chair), (chair, will), (will, be), (be,...  \n",
       "\n",
       "[1 rows x 55 columns]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_data_deleted['Freq_unigram'] = new_data_deleted.apply(lambda row: Freq_Unigram(row['Clean']), axis = 1)\n",
    "new_data_deleted['Freq_bigram'] = new_data_deleted.apply(lambda row: Freq_Bigram(row['Clean']), axis = 1)\n",
    "\n",
    "new_data_deleted.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "c745dc17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Author</th>\n",
       "      <th>Content</th>\n",
       "      <th>Following</th>\n",
       "      <th>Followers</th>\n",
       "      <th>Tweet_id</th>\n",
       "      <th>Deleted</th>\n",
       "      <th>Clean</th>\n",
       "      <th>Postags</th>\n",
       "      <th>LS</th>\n",
       "      <th>TO</th>\n",
       "      <th>...</th>\n",
       "      <th>WRB</th>\n",
       "      <th>NNP</th>\n",
       "      <th>EX</th>\n",
       "      <th>NNS</th>\n",
       "      <th>SYM</th>\n",
       "      <th>CC</th>\n",
       "      <th>CD</th>\n",
       "      <th>POS</th>\n",
       "      <th>Freq_unigram</th>\n",
       "      <th>Freq_bigram</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ROOMOFRUMOR</td>\n",
       "      <td>IAAF chief Coe says corruption claims 'abhorre...</td>\n",
       "      <td>8724</td>\n",
       "      <td>12308</td>\n",
       "      <td>6.630000e+17</td>\n",
       "      <td>0</td>\n",
       "      <td>iaaf chief coe says corruption claims abhorren...</td>\n",
       "      <td>[NN, NN, NN, VBZ, NN, NNS, JJ, NNS]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[iaaf, chief, coe, says, corruption, claims, a...</td>\n",
       "      <td>[(iaaf, chief), (chief, coe), (coe, says), (sa...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 55 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Author                                            Content  Following  \\\n",
       "0  ROOMOFRUMOR  IAAF chief Coe says corruption claims 'abhorre...       8724   \n",
       "\n",
       "   Followers      Tweet_id  Deleted  \\\n",
       "0      12308  6.630000e+17        0   \n",
       "\n",
       "                                               Clean  \\\n",
       "0  iaaf chief coe says corruption claims abhorren...   \n",
       "\n",
       "                               Postags   LS   TO  ...  WRB  NNP   EX   NNS  \\\n",
       "0  [NN, NN, NN, VBZ, NN, NNS, JJ, NNS]  0.0  0.0  ...  0.0  0.0  0.0  0.25   \n",
       "\n",
       "   SYM   CC   CD  POS                                       Freq_unigram  \\\n",
       "0  0.0  0.0  0.0  0.0  [iaaf, chief, coe, says, corruption, claims, a...   \n",
       "\n",
       "                                         Freq_bigram  \n",
       "0  [(iaaf, chief), (chief, coe), (coe, says), (sa...  \n",
       "\n",
       "[1 rows x 55 columns]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "legitmate_data['Freq_unigram'] = legitmate_data.apply(lambda row: Freq_Unigram(row['Clean']), axis = 1)\n",
    "legitmate_data['Freq_bigram'] = legitmate_data.apply(lambda row: Freq_Bigram(row['Clean']), axis = 1)\n",
    "\n",
    "legitmate_data.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "62ba2832",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "39995"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a library for unigram deleted data\n",
    "Unigram_lib_d=[]\n",
    "for i in range(len(new_data_deleted)):\n",
    "    u =new_data_deleted['Freq_unigram'][i]\n",
    "    Unigram_lib_d.append(u)\n",
    "\n",
    "Uni_list_d=[]\n",
    "for i in Unigram_lib_d:\n",
    "    for j in i:\n",
    "        Uni_list_d.append(j)\n",
    "        \n",
    "len(Uni_list_d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "488d620c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7144"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def unique(list1):\n",
    "    output = set()\n",
    "    for x in list1:\n",
    "        output.add(x)\n",
    "    return output\n",
    "\n",
    "Unigram_library_deleted = unique(Uni_list_d)\n",
    "len(Unigram_library_deleted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "ddaa12b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "35777"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a library for unigram legitimate data\n",
    "Unigram_lib_l=[]\n",
    "for i in range(len(legitmate_data)):\n",
    "    u =legitmate_data['Freq_unigram'][i]\n",
    "    Unigram_lib_l.append(u)\n",
    "\n",
    "Uni_list_l=[]\n",
    "for i in Unigram_lib_l:\n",
    "    for j in i:\n",
    "        Uni_list_l.append(j)\n",
    "        \n",
    "len(Uni_list_l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "1f6ebb95",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8579"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Unigram_library_legitmate = unique(Uni_list_l)\n",
    "len(Unigram_library_legitmate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "99bace23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a library for bigram\n",
    "Bigram_lib=[]\n",
    "for i in range(len(new_data_deleted)):\n",
    "    b =new_data_deleted['Freq_bigram'][i]    \n",
    "    Bigram_lib.append(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "c358007f",
   "metadata": {},
   "outputs": [],
   "source": [
    "Bi_list=[]\n",
    "for i in Bigram_lib:\n",
    "    for j in i:\n",
    "        Bi_list.append(j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "74db3569",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26827"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Bigram_library = unique(Bi_list)\n",
    "len(Bigram_library)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "da0fb479",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Maryam\\AppData\\Local\\Temp/ipykernel_5124/3087835662.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_data_deleted[i]=np.zeros(3000)\n"
     ]
    }
   ],
   "source": [
    "for i in list(Unigram_library_deleted):\n",
    "     new_data_deleted[i]=np.zeros(3000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "e4b0769f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Maryam\\AppData\\Local\\Temp/ipykernel_5124/3632394950.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  legitmate_data[i]=np.zeros(3000)\n"
     ]
    }
   ],
   "source": [
    "for i in list(Unigram_library_legitmate):\n",
    "     legitmate_data[i]=np.zeros(3000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "37149942",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Maryam\\AppData\\Local\\Temp/ipykernel_5124/599738801.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  new_data_deleted[i][j]=new_data_deleted[i][j]+1\n"
     ]
    }
   ],
   "source": [
    "for j in range(len(new_data_deleted)):\n",
    "    for i in new_data_deleted['Freq_unigram'][j]:\n",
    "        new_data_deleted[i][j]=new_data_deleted[i][j]+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "49efe768",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Maryam\\AppData\\Local\\Temp/ipykernel_5124/2033997526.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  legitmate_data[i][j]=legitmate_data[i][j]+1\n"
     ]
    }
   ],
   "source": [
    "for j in range(len(legitmate_data)):\n",
    "    for i in legitmate_data['Freq_unigram'][j]:\n",
    "        legitmate_data[i][j]=legitmate_data[i][j]+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "836b008d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(new_data_deleted)):\n",
    "     new_data_deleted.iloc[i, 55:7199]=new_data_deleted.iloc[i, 55:7199]/len(new_data_deleted['Freq_unigram'][i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "9ef4742e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(legitmate_data)):\n",
    "     legitmate_data.iloc[i, 55:8634]=legitmate_data.iloc[i, 55:8634]/len(legitmate_data['Freq_unigram'][i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "b8333de3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk, re, pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "f6d4d79e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def token(row):\n",
    "    nltk_pos_tagged = nltk.pos_tag(row.split())\n",
    "    return nltk_pos_tagged\n",
    "\n",
    "def phrase_tag(row):\n",
    "    grammar = r\"\"\"\n",
    "    NP: {<DT|JJ|NN.*>+}          # Chunk sequences of DT, JJ, NN\n",
    "    PP: {<IN><NP>}               # Chunk prepositions followed by NP\n",
    "    VP: {<VB.*><NP|PP|CLAUSE>+$} # Chunk verbs and their arguments\n",
    "    CLAUSE: {<NP><VP>}           # Chunk NP, VP\n",
    "    \"\"\"\n",
    "    cp = nltk.RegexpParser(grammar, loop=2)\n",
    "    result = cp.parse(token(row))\n",
    "    return(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "8d716ad3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n"
     ]
    }
   ],
   "source": [
    "new_data_deleted['phrase_tag'] = new_data_deleted.apply(lambda row: phrase_tag(row['Clean']), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "3871d36a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<svg baseProfile=\"full\" height=\"264px\" preserveAspectRatio=\"xMidYMid meet\" style=\"font-family: times, serif; font-weight:normal; font-style: normal; font-size: 16px;\" version=\"1.1\" viewBox=\"0,0,528.0,264.0\" width=\"528px\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:ev=\"http://www.w3.org/2001/xml-events\" xmlns:xlink=\"http://www.w3.org/1999/xlink\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">S</text></svg><svg width=\"18.1818%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">NP</text></svg><svg width=\"41.6667%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">rnc</text></svg><svg width=\"100%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">NN</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"20.8333%\" y1=\"1.2em\" y2=\"3em\" /><svg width=\"58.3333%\" x=\"41.6667%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">chair</text></svg><svg width=\"100%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">NN</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"70.8333%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"9.09091%\" y1=\"1.2em\" y2=\"3em\" /><svg width=\"9.09091%\" x=\"18.1818%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">will</text></svg><svg width=\"100%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">MD</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"22.7273%\" y1=\"1.2em\" y2=\"3em\" /><svg width=\"72.7273%\" x=\"27.2727%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">VP</text></svg><svg width=\"8.33333%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">be</text></svg><svg width=\"100%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">VB</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"4.16667%\" y1=\"1.2em\" y2=\"3em\" /><svg width=\"22.9167%\" x=\"8.33333%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">PP</text></svg><svg width=\"36.3636%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">on</text></svg><svg width=\"100%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">IN</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"18.1818%\" y1=\"1.2em\" y2=\"3em\" /><svg width=\"63.6364%\" x=\"36.3636%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">NP</text></svg><svg width=\"100%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">cspan</text></svg><svg width=\"100%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">NN</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"68.1818%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"19.7917%\" y1=\"1.2em\" y2=\"3em\" /><svg width=\"43.75%\" x=\"31.25%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">PP</text></svg><svg width=\"38.0952%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">around</text></svg><svg width=\"100%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">IN</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"19.0476%\" y1=\"1.2em\" y2=\"3em\" /><svg width=\"61.9048%\" x=\"38.0952%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">NP</text></svg><svg width=\"30.7692%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">pm</text></svg><svg width=\"100%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">JJ</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"15.3846%\" y1=\"1.2em\" y2=\"3em\" /><svg width=\"69.2308%\" x=\"30.7692%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">tonight</text></svg><svg width=\"100%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">NN</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"65.3846%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"69.0476%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"53.125%\" y1=\"1.2em\" y2=\"3em\" /><svg width=\"25%\" x=\"75%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">PP</text></svg><svg width=\"50%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">from</text></svg><svg width=\"100%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">IN</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"25%\" y1=\"1.2em\" y2=\"3em\" /><svg width=\"50%\" x=\"50%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">NP</text></svg><svg width=\"100%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">cpac</text></svg><svg width=\"100%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">NN</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"75%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"87.5%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"63.6364%\" y1=\"1.2em\" y2=\"3em\" /></svg>"
      ],
      "text/plain": [
       "Tree('S', [Tree('NP', [('rnc', 'NN'), ('chair', 'NN')]), ('will', 'MD'), Tree('VP', [('be', 'VB'), Tree('PP', [('on', 'IN'), Tree('NP', [('cspan', 'NN')])]), Tree('PP', [('around', 'IN'), Tree('NP', [('pm', 'JJ'), ('tonight', 'NN')])]), Tree('PP', [('from', 'IN'), Tree('NP', [('cpac', 'NN')])])])])"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_data_deleted['phrase_tag'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "55aeba1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n"
     ]
    }
   ],
   "source": [
    "legitmate_data['phrase_tag'] = legitmate_data.apply(lambda row: phrase_tag(row['Clean']), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "356ef932",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3000, 7200)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_data_deleted.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "a6df4687",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3000, 8635)"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "legitmate_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "2e4595df",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "def token(row):\n",
    "    nltk_pos_tagged = nltk.pos_tag(row.split())\n",
    "    return nltk_pos_tagged\n",
    "\n",
    "def Freq_phrase_tag_VP(row):\n",
    "    grammar = r\"\"\"\n",
    "    NP: {<DT|JJ|NN.*>+}          # Chunk sequences of DT, JJ, NN\n",
    "    PP: {<IN><NP>}               # Chunk prepositions followed by NP\n",
    "    VP: {<VB.*><NP|PP|CLAUSE>+$} # Chunk verbs and their arguments\n",
    "    CLAUSE: {<NP><VP>}           # Chunk NP, VP\n",
    "    \"\"\"\n",
    "    cp = nltk.RegexpParser(grammar, loop=2)\n",
    "    result = cp.parse(token(row))\n",
    "    #return(result)\n",
    "    \n",
    "    pp=str(result).split()\n",
    "    tags_counts = Counter(pp)\n",
    "    VP=tags_counts['(VP']\n",
    "    #NP=tags_counts['(NP']\n",
    "    return VP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "ab81bf49",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "def token(row):\n",
    "    nltk_pos_tagged = nltk.pos_tag(row.split())\n",
    "    return nltk_pos_tagged\n",
    "\n",
    "def Freq_phrase_tag_NP(row):\n",
    "    grammar = r\"\"\"\n",
    "    NP: {<DT|JJ|NN.*>+}          # Chunk sequences of DT, JJ, NN\n",
    "    PP: {<IN><NP>}               # Chunk prepositions followed by NP\n",
    "    VP: {<VB.*><NP|PP|CLAUSE>+$} # Chunk verbs and their arguments\n",
    "    CLAUSE: {<NP><VP>}           # Chunk NP, VP\n",
    "    \"\"\"\n",
    "    cp = nltk.RegexpParser(grammar, loop=2)\n",
    "    result = cp.parse(token(row))\n",
    "    #return(result)\n",
    "    \n",
    "    pp=str(result).split()\n",
    "    tags_counts = Counter(pp)\n",
    "    #VP=tags_counts['(VP']\n",
    "    NP=tags_counts['(NP']\n",
    "    return  NP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "763fa738",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n"
     ]
    }
   ],
   "source": [
    "new_data_deleted['VP'] = new_data_deleted.apply(lambda row: Freq_phrase_tag_VP(row['Clean']), axis = 1)\n",
    "legitmate_data['VP'] = legitmate_data.apply(lambda row: Freq_phrase_tag_VP(row['Clean']), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "fb308c1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n"
     ]
    }
   ],
   "source": [
    "new_data_deleted['NP'] = new_data_deleted.apply(lambda row: Freq_phrase_tag_NP(row['Clean']), axis = 1)\n",
    "legitmate_data['NP'] = legitmate_data.apply(lambda row: Freq_phrase_tag_NP(row['Clean']), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "d55b4d1c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3000, 7202)"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_data_deleted.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "3db4295f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(new_data_deleted)):\n",
    "     new_data_deleted.iloc[i,7200:7202]=new_data_deleted.iloc[i,7200:7202]/(new_data_deleted.iloc[i,7200]+new_data_deleted.iloc[i,7201])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "e75f9a77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Author</th>\n",
       "      <th>Content</th>\n",
       "      <th>Tweet_id</th>\n",
       "      <th>Following</th>\n",
       "      <th>Followers</th>\n",
       "      <th>Deleted</th>\n",
       "      <th>Clean</th>\n",
       "      <th>Postags</th>\n",
       "      <th>LS</th>\n",
       "      <th>TO</th>\n",
       "      <th>...</th>\n",
       "      <th>great</th>\n",
       "      <th>bt</th>\n",
       "      <th>tubman</th>\n",
       "      <th>stick</th>\n",
       "      <th>werent</th>\n",
       "      <th>fast</th>\n",
       "      <th>jc</th>\n",
       "      <th>phrase_tag</th>\n",
       "      <th>VP</th>\n",
       "      <th>NP</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sean Spicer</td>\n",
       "      <td>RNC Chair @rnc @ReincePriebus will be on CSPAN...</td>\n",
       "      <td>1.680000e+17</td>\n",
       "      <td>995</td>\n",
       "      <td>448K</td>\n",
       "      <td>1</td>\n",
       "      <td>rnc chair will be on cspan around pm tonight f...</td>\n",
       "      <td>[NN, NN, VBP, IN, NN, NN, NN]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[[(rnc, NN), (chair, NN)], (will, MD), [(be, V...</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Sean Spicer</td>\n",
       "      <td>Want to know the real cost of Obamacare http:/...</td>\n",
       "      <td>1.250000e+17</td>\n",
       "      <td>995</td>\n",
       "      <td>448K</td>\n",
       "      <td>1</td>\n",
       "      <td>want to know the real cost of obamacare</td>\n",
       "      <td>[NN, VB, JJ, NN, NN]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[[(want, NN)], (to, TO), [(know, VB), [('the',...</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Sean Spicer</td>\n",
       "      <td>.@rollcall @pennstatetom makes the case for ph...</td>\n",
       "      <td>6.750000e+17</td>\n",
       "      <td>995</td>\n",
       "      <td>448K</td>\n",
       "      <td>1</td>\n",
       "      <td>makes the case for photographers media walk thru</td>\n",
       "      <td>[VBZ, NN, NNS, NNS, VBP, NN]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[(makes, VBZ), [(the, DT), (case, NN)], [(for,...</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Ben &amp; Candy Carson</td>\n",
       "      <td>Building strong relationships will #HealInspir...</td>\n",
       "      <td>6.520000e+17</td>\n",
       "      <td>50</td>\n",
       "      <td>2.2M</td>\n",
       "      <td>1</td>\n",
       "      <td>building strong relationships will healinspire...</td>\n",
       "      <td>[NN, JJ, NNS, JJ, NN]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[[(building, NN), (strong, JJ), (relationships...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Larry Kudlow</td>\n",
       "      <td>@noellenikpour @StephenMoore @batchelorshow @M...</td>\n",
       "      <td>5.170000e+17</td>\n",
       "      <td>322</td>\n",
       "      <td>235.9</td>\n",
       "      <td>1</td>\n",
       "      <td>hi noelle please give me a yell</td>\n",
       "      <td>[NN, JJ, NN, VB, NN]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[[(hi, NN), (noelle, JJ), (please, NN)], (give...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 7202 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               Author                                            Content  \\\n",
       "0         Sean Spicer  RNC Chair @rnc @ReincePriebus will be on CSPAN...   \n",
       "1         Sean Spicer  Want to know the real cost of Obamacare http:/...   \n",
       "2         Sean Spicer  .@rollcall @pennstatetom makes the case for ph...   \n",
       "3  Ben & Candy Carson  Building strong relationships will #HealInspir...   \n",
       "4        Larry Kudlow  @noellenikpour @StephenMoore @batchelorshow @M...   \n",
       "\n",
       "       Tweet_id Following Followers  Deleted  \\\n",
       "0  1.680000e+17       995      448K        1   \n",
       "1  1.250000e+17       995      448K        1   \n",
       "2  6.750000e+17       995      448K        1   \n",
       "3  6.520000e+17        50      2.2M        1   \n",
       "4  5.170000e+17       322     235.9        1   \n",
       "\n",
       "                                               Clean  \\\n",
       "0  rnc chair will be on cspan around pm tonight f...   \n",
       "1            want to know the real cost of obamacare   \n",
       "2   makes the case for photographers media walk thru   \n",
       "3  building strong relationships will healinspire...   \n",
       "4                    hi noelle please give me a yell   \n",
       "\n",
       "                         Postags   LS   TO  ...  great   bt  tubman  stick  \\\n",
       "0  [NN, NN, VBP, IN, NN, NN, NN]  0.0  0.0  ...    0.0  0.0     0.0    0.0   \n",
       "1           [NN, VB, JJ, NN, NN]  0.0  0.0  ...    0.0  0.0     0.0    0.0   \n",
       "2   [VBZ, NN, NNS, NNS, VBP, NN]  0.0  0.0  ...    0.0  0.0     0.0    0.0   \n",
       "3          [NN, JJ, NNS, JJ, NN]  0.0  0.0  ...    0.0  0.0     0.0    0.0   \n",
       "4           [NN, JJ, NN, VB, NN]  0.0  0.0  ...    0.0  0.0     0.0    0.0   \n",
       "\n",
       "   werent  fast   jc                                         phrase_tag    VP  \\\n",
       "0     0.0   0.0  0.0  [[(rnc, NN), (chair, NN)], (will, MD), [(be, V...  0.20   \n",
       "1     0.0   0.0  0.0  [[(want, NN)], (to, TO), [(know, VB), [('the',...  0.25   \n",
       "2     0.0   0.0  0.0  [(makes, VBZ), [(the, DT), (case, NN)], [(for,...  0.25   \n",
       "3     0.0   0.0  0.0  [[(building, NN), (strong, JJ), (relationships...  0.00   \n",
       "4     0.0   0.0  0.0  [[(hi, NN), (noelle, JJ), (please, NN)], (give...  0.00   \n",
       "\n",
       "     NP  \n",
       "0  0.80  \n",
       "1  0.75  \n",
       "2  0.75  \n",
       "3  1.00  \n",
       "4  1.00  \n",
       "\n",
       "[5 rows x 7202 columns]"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_data_deleted.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "bf9e4899",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3000, 8637)"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "legitmate_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "a75cbd38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "legitmate_data.iloc[0,8635]+legitmate_data.iloc[0,8636]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "2f55820e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(legitmate_data)):\n",
    "     legitmate_data.iloc[i,8635:8637]=legitmate_data.iloc[i,8635:8637]/(legitmate_data.iloc[i,8635]+legitmate_data.iloc[i,8636])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "ed1a9d4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Author</th>\n",
       "      <th>Content</th>\n",
       "      <th>Following</th>\n",
       "      <th>Followers</th>\n",
       "      <th>Tweet_id</th>\n",
       "      <th>Deleted</th>\n",
       "      <th>Clean</th>\n",
       "      <th>Postags</th>\n",
       "      <th>LS</th>\n",
       "      <th>TO</th>\n",
       "      <th>...</th>\n",
       "      <th>allowing</th>\n",
       "      <th>rips</th>\n",
       "      <th>bibi</th>\n",
       "      <th>hope</th>\n",
       "      <th>great</th>\n",
       "      <th>playoffs</th>\n",
       "      <th>foo</th>\n",
       "      <th>phrase_tag</th>\n",
       "      <th>VP</th>\n",
       "      <th>NP</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ROOMOFRUMOR</td>\n",
       "      <td>IAAF chief Coe says corruption claims 'abhorre...</td>\n",
       "      <td>8724</td>\n",
       "      <td>12308</td>\n",
       "      <td>6.630000e+17</td>\n",
       "      <td>0</td>\n",
       "      <td>iaaf chief coe says corruption claims abhorren...</td>\n",
       "      <td>[NN, NN, NN, VBZ, NN, NNS, JJ, NNS]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[[[('iaaf', 'NN'), ('chief', 'NN'), ('coe', 'N...</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>JOHJOHHO</td>\n",
       "      <td>https://t.co/wwwUQ32qGV #BritainInOut #Goodbye...</td>\n",
       "      <td>105</td>\n",
       "      <td>11</td>\n",
       "      <td>7.460000e+17</td>\n",
       "      <td>0</td>\n",
       "      <td>britaininout goodbyeuk remainineu euref</td>\n",
       "      <td>[IN, JJ, NN, NN]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[[(britaininout, IN), [('goodbyeuk', 'JJ'), ('...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SEATTLE_POST</td>\n",
       "      <td>Pennsylvania Democrats pick establishment’s Se...</td>\n",
       "      <td>4427</td>\n",
       "      <td>15633</td>\n",
       "      <td>7.250000e+17</td>\n",
       "      <td>0</td>\n",
       "      <td>pennsylvania democrats pick establishment s se...</td>\n",
       "      <td>[NN, NNS, VBP, JJ, NN, NN, NN]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[[[('pennsylvania', 'NN'), ('democrats', 'NNS'...</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ROOMOFRUMOR</td>\n",
       "      <td>Last year's runner-up Johnson in buoyant mood ...</td>\n",
       "      <td>8598</td>\n",
       "      <td>12284</td>\n",
       "      <td>7.430000e+17</td>\n",
       "      <td>0</td>\n",
       "      <td>last year s runner up johnson in buoyant mood ...</td>\n",
       "      <td>[JJ, NN, NN, NN, JJ, NN, JJ, NNS]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[[(last, JJ), (year, NN)], (s, VBD), (runner, ...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>KANSASDAILYNEWS</td>\n",
       "      <td>Theft of construction equipment from Wamego bu...</td>\n",
       "      <td>5148</td>\n",
       "      <td>24459</td>\n",
       "      <td>7.200000e+17</td>\n",
       "      <td>0</td>\n",
       "      <td>theft of construction equipment from wamego bu...</td>\n",
       "      <td>[NN, NN, NN, NN, NN, VBD, NN, NN]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[[(theft, NN)], [(of, IN), [('construction', '...</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.800000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 8637 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Author                                            Content  \\\n",
       "0      ROOMOFRUMOR  IAAF chief Coe says corruption claims 'abhorre...   \n",
       "1         JOHJOHHO  https://t.co/wwwUQ32qGV #BritainInOut #Goodbye...   \n",
       "2     SEATTLE_POST  Pennsylvania Democrats pick establishment’s Se...   \n",
       "3      ROOMOFRUMOR  Last year's runner-up Johnson in buoyant mood ...   \n",
       "4  KANSASDAILYNEWS  Theft of construction equipment from Wamego bu...   \n",
       "\n",
       "   Following  Followers      Tweet_id  Deleted  \\\n",
       "0       8724      12308  6.630000e+17        0   \n",
       "1        105         11  7.460000e+17        0   \n",
       "2       4427      15633  7.250000e+17        0   \n",
       "3       8598      12284  7.430000e+17        0   \n",
       "4       5148      24459  7.200000e+17        0   \n",
       "\n",
       "                                               Clean  \\\n",
       "0  iaaf chief coe says corruption claims abhorren...   \n",
       "1            britaininout goodbyeuk remainineu euref   \n",
       "2  pennsylvania democrats pick establishment s se...   \n",
       "3  last year s runner up johnson in buoyant mood ...   \n",
       "4  theft of construction equipment from wamego bu...   \n",
       "\n",
       "                               Postags   LS   TO  ...  allowing  rips  bibi  \\\n",
       "0  [NN, NN, NN, VBZ, NN, NNS, JJ, NNS]  0.0  0.0  ...       0.0   0.0   0.0   \n",
       "1                     [IN, JJ, NN, NN]  0.0  0.0  ...       0.0   0.0   0.0   \n",
       "2       [NN, NNS, VBP, JJ, NN, NN, NN]  0.0  0.0  ...       0.0   0.0   0.0   \n",
       "3    [JJ, NN, NN, NN, JJ, NN, JJ, NNS]  0.0  0.0  ...       0.0   0.0   0.0   \n",
       "4    [NN, NN, NN, NN, NN, VBD, NN, NN]  0.0  0.0  ...       0.0   0.0   0.0   \n",
       "\n",
       "   hope  great  playoffs  foo  \\\n",
       "0   0.0    0.0       0.0  0.0   \n",
       "1   0.0    0.0       0.0  0.0   \n",
       "2   0.0    0.0       0.0  0.0   \n",
       "3   0.0    0.0       0.0  0.0   \n",
       "4   0.0    0.0       0.0  0.0   \n",
       "\n",
       "                                          phrase_tag        VP        NP  \n",
       "0  [[[('iaaf', 'NN'), ('chief', 'NN'), ('coe', 'N...  0.333333  0.666667  \n",
       "1  [[(britaininout, IN), [('goodbyeuk', 'JJ'), ('...  0.000000  1.000000  \n",
       "2  [[[('pennsylvania', 'NN'), ('democrats', 'NNS'...  0.333333  0.666667  \n",
       "3  [[(last, JJ), (year, NN)], (s, VBD), (runner, ...  0.000000  1.000000  \n",
       "4  [[(theft, NN)], [(of, IN), [('construction', '...  0.200000  0.800000  \n",
       "\n",
       "[5 rows x 8637 columns]"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "legitmate_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "3cc19d53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of missing points in new_data_deleted Author         0\n",
      "Content        0\n",
      "Tweet_id       0\n",
      "Following      0\n",
      "Followers      0\n",
      "              ..\n",
      "fast          18\n",
      "jc            18\n",
      "phrase_tag     0\n",
      "VP            63\n",
      "NP            63\n",
      "Length: 7202, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# get the number of missing data points for Deleted data\n",
    "missing_values_count_new_data_deleted = new_data_deleted.isnull().sum()\n",
    "print('Number of missing points in new_data_deleted',missing_values_count_new_data_deleted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "262721fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The total percent of data in new_data_deleted missing is 0.6009580672035546\n"
     ]
    }
   ],
   "source": [
    "# how many total missing values do we have?\n",
    "total_cells = np.product(new_data_deleted.shape)\n",
    "total_missing = missing_values_count_new_data_deleted.sum()\n",
    "\n",
    "# percent of data that is missing\n",
    "percent_missing = (total_missing/total_cells) * 100\n",
    "print('The total percent of data in new_data_deleted missing is',percent_missing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "58525755",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of missing points in new_data_deleted Author         0\n",
      "Content        0\n",
      "Following      0\n",
      "Followers      0\n",
      "Tweet_id       0\n",
      "              ..\n",
      "playoffs       9\n",
      "foo            9\n",
      "phrase_tag     0\n",
      "VP            19\n",
      "NP            19\n",
      "Length: 8637, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# get the number of missing data points for legitmate_data\n",
    "missing_values_count_legitmate_data = legitmate_data.isnull().sum()\n",
    "print('Number of missing points in new_data_deleted',missing_values_count_legitmate_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "39853930",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The total percent of data in legitmate_data missing is 0.3002161244259195\n"
     ]
    }
   ],
   "source": [
    "# how many total missing values do we have?\n",
    "total_cells = np.product(legitmate_data.shape)\n",
    "total_missing = missing_values_count_legitmate_data.sum()\n",
    "\n",
    "# percent of data that is missing\n",
    "percent_missing = (total_missing/total_cells) * 100\n",
    "print('The total percent of data in legitmate_data missing is',percent_missing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "2ba62421",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove all the rows that contain a missing value\n",
    "Clean_new_data_deleted= new_data_deleted.dropna()\n",
    "Clean_legitmate_data= legitmate_data.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "84482123",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2936, 7202)"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Clean_new_data_deleted.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "a9c7760b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2980, 8637)"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Clean_legitmate_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "85f4c457",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean_new_data_deleted.to_csv('Last_version_deleted.csv', index = False, encoding='utf-8-sig')\n",
    "# Clean_legitmate_data.to_csv('Last_version_legitmate.csv', index = False, encoding='utf-8-sig')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "71dfbfae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Author</th>\n",
       "      <th>Content</th>\n",
       "      <th>Tweet_id</th>\n",
       "      <th>Following</th>\n",
       "      <th>Followers</th>\n",
       "      <th>Deleted</th>\n",
       "      <th>Clean</th>\n",
       "      <th>Postags</th>\n",
       "      <th>LS</th>\n",
       "      <th>TO</th>\n",
       "      <th>...</th>\n",
       "      <th>MD</th>\n",
       "      <th>VB</th>\n",
       "      <th>WRB</th>\n",
       "      <th>NNP</th>\n",
       "      <th>EX</th>\n",
       "      <th>NNS</th>\n",
       "      <th>SYM</th>\n",
       "      <th>CC</th>\n",
       "      <th>CD</th>\n",
       "      <th>POS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sean Spicer</td>\n",
       "      <td>RNC Chair @rnc @ReincePriebus will be on CSPAN...</td>\n",
       "      <td>1.680000e+17</td>\n",
       "      <td>995</td>\n",
       "      <td>448K</td>\n",
       "      <td>1</td>\n",
       "      <td>rnc chair will be on cspan around pm tonight f...</td>\n",
       "      <td>[NN, NN, VBP, IN, NN, NN, NN]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Sean Spicer</td>\n",
       "      <td>Want to know the real cost of Obamacare http:/...</td>\n",
       "      <td>1.250000e+17</td>\n",
       "      <td>995</td>\n",
       "      <td>448K</td>\n",
       "      <td>1</td>\n",
       "      <td>want to know the real cost of obamacare</td>\n",
       "      <td>[NN, VB, JJ, NN, NN]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Sean Spicer</td>\n",
       "      <td>.@rollcall @pennstatetom makes the case for ph...</td>\n",
       "      <td>6.750000e+17</td>\n",
       "      <td>995</td>\n",
       "      <td>448K</td>\n",
       "      <td>1</td>\n",
       "      <td>makes the case for photographers media walk thru</td>\n",
       "      <td>[VBZ, NN, NNS, NNS, VBP, NN]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Ben &amp; Candy Carson</td>\n",
       "      <td>Building strong relationships will #HealInspir...</td>\n",
       "      <td>6.520000e+17</td>\n",
       "      <td>50</td>\n",
       "      <td>2.2M</td>\n",
       "      <td>1</td>\n",
       "      <td>building strong relationships will healinspire...</td>\n",
       "      <td>[NN, JJ, NNS, JJ, NN]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Larry Kudlow</td>\n",
       "      <td>@noellenikpour @StephenMoore @batchelorshow @M...</td>\n",
       "      <td>5.170000e+17</td>\n",
       "      <td>322</td>\n",
       "      <td>235.9</td>\n",
       "      <td>1</td>\n",
       "      <td>hi noelle please give me a yell</td>\n",
       "      <td>[NN, JJ, NN, VB, NN]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 53 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               Author                                            Content  \\\n",
       "0         Sean Spicer  RNC Chair @rnc @ReincePriebus will be on CSPAN...   \n",
       "1         Sean Spicer  Want to know the real cost of Obamacare http:/...   \n",
       "2         Sean Spicer  .@rollcall @pennstatetom makes the case for ph...   \n",
       "3  Ben & Candy Carson  Building strong relationships will #HealInspir...   \n",
       "4        Larry Kudlow  @noellenikpour @StephenMoore @batchelorshow @M...   \n",
       "\n",
       "       Tweet_id Following Followers  Deleted  \\\n",
       "0  1.680000e+17       995      448K        1   \n",
       "1  1.250000e+17       995      448K        1   \n",
       "2  6.750000e+17       995      448K        1   \n",
       "3  6.520000e+17        50      2.2M        1   \n",
       "4  5.170000e+17       322     235.9        1   \n",
       "\n",
       "                                               Clean  \\\n",
       "0  rnc chair will be on cspan around pm tonight f...   \n",
       "1            want to know the real cost of obamacare   \n",
       "2   makes the case for photographers media walk thru   \n",
       "3  building strong relationships will healinspire...   \n",
       "4                    hi noelle please give me a yell   \n",
       "\n",
       "                         Postags   LS   TO  ...   MD   VB  WRB  NNP   EX  \\\n",
       "0  [NN, NN, VBP, IN, NN, NN, NN]  0.0  0.0  ...  0.0  0.0  0.0  0.0  0.0   \n",
       "1           [NN, VB, JJ, NN, NN]  0.0  0.0  ...  0.0  0.2  0.0  0.0  0.0   \n",
       "2   [VBZ, NN, NNS, NNS, VBP, NN]  0.0  0.0  ...  0.0  0.0  0.0  0.0  0.0   \n",
       "3          [NN, JJ, NNS, JJ, NN]  0.0  0.0  ...  0.0  0.0  0.0  0.0  0.0   \n",
       "4           [NN, JJ, NN, VB, NN]  0.0  0.0  ...  0.0  0.2  0.0  0.0  0.0   \n",
       "\n",
       "        NNS  SYM   CC   CD  POS  \n",
       "0  0.000000  0.0  0.0  0.0  0.0  \n",
       "1  0.000000  0.0  0.0  0.0  0.0  \n",
       "2  0.333333  0.0  0.0  0.0  0.0  \n",
       "3  0.200000  0.0  0.0  0.0  0.0  \n",
       "4  0.000000  0.0  0.0  0.0  0.0  \n",
       "\n",
       "[5 rows x 53 columns]"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_deleted_pos = Clean_new_data_deleted.iloc[:,:53]\n",
    "df_deleted_pos.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "0c525ba7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Author</th>\n",
       "      <th>Content</th>\n",
       "      <th>Following</th>\n",
       "      <th>Followers</th>\n",
       "      <th>Tweet_id</th>\n",
       "      <th>Deleted</th>\n",
       "      <th>Clean</th>\n",
       "      <th>Postags</th>\n",
       "      <th>LS</th>\n",
       "      <th>TO</th>\n",
       "      <th>...</th>\n",
       "      <th>MD</th>\n",
       "      <th>VB</th>\n",
       "      <th>WRB</th>\n",
       "      <th>NNP</th>\n",
       "      <th>EX</th>\n",
       "      <th>NNS</th>\n",
       "      <th>SYM</th>\n",
       "      <th>CC</th>\n",
       "      <th>CD</th>\n",
       "      <th>POS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ROOMOFRUMOR</td>\n",
       "      <td>IAAF chief Coe says corruption claims 'abhorre...</td>\n",
       "      <td>8724</td>\n",
       "      <td>12308</td>\n",
       "      <td>6.630000e+17</td>\n",
       "      <td>0</td>\n",
       "      <td>iaaf chief coe says corruption claims abhorren...</td>\n",
       "      <td>[NN, NN, NN, VBZ, NN, NNS, JJ, NNS]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>JOHJOHHO</td>\n",
       "      <td>https://t.co/wwwUQ32qGV #BritainInOut #Goodbye...</td>\n",
       "      <td>105</td>\n",
       "      <td>11</td>\n",
       "      <td>7.460000e+17</td>\n",
       "      <td>0</td>\n",
       "      <td>britaininout goodbyeuk remainineu euref</td>\n",
       "      <td>[IN, JJ, NN, NN]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SEATTLE_POST</td>\n",
       "      <td>Pennsylvania Democrats pick establishment’s Se...</td>\n",
       "      <td>4427</td>\n",
       "      <td>15633</td>\n",
       "      <td>7.250000e+17</td>\n",
       "      <td>0</td>\n",
       "      <td>pennsylvania democrats pick establishment s se...</td>\n",
       "      <td>[NN, NNS, VBP, JJ, NN, NN, NN]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ROOMOFRUMOR</td>\n",
       "      <td>Last year's runner-up Johnson in buoyant mood ...</td>\n",
       "      <td>8598</td>\n",
       "      <td>12284</td>\n",
       "      <td>7.430000e+17</td>\n",
       "      <td>0</td>\n",
       "      <td>last year s runner up johnson in buoyant mood ...</td>\n",
       "      <td>[JJ, NN, NN, NN, JJ, NN, JJ, NNS]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>KANSASDAILYNEWS</td>\n",
       "      <td>Theft of construction equipment from Wamego bu...</td>\n",
       "      <td>5148</td>\n",
       "      <td>24459</td>\n",
       "      <td>7.200000e+17</td>\n",
       "      <td>0</td>\n",
       "      <td>theft of construction equipment from wamego bu...</td>\n",
       "      <td>[NN, NN, NN, NN, NN, VBD, NN, NN]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 53 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Author                                            Content  \\\n",
       "0      ROOMOFRUMOR  IAAF chief Coe says corruption claims 'abhorre...   \n",
       "1         JOHJOHHO  https://t.co/wwwUQ32qGV #BritainInOut #Goodbye...   \n",
       "2     SEATTLE_POST  Pennsylvania Democrats pick establishment’s Se...   \n",
       "3      ROOMOFRUMOR  Last year's runner-up Johnson in buoyant mood ...   \n",
       "4  KANSASDAILYNEWS  Theft of construction equipment from Wamego bu...   \n",
       "\n",
       "   Following  Followers      Tweet_id  Deleted  \\\n",
       "0       8724      12308  6.630000e+17        0   \n",
       "1        105         11  7.460000e+17        0   \n",
       "2       4427      15633  7.250000e+17        0   \n",
       "3       8598      12284  7.430000e+17        0   \n",
       "4       5148      24459  7.200000e+17        0   \n",
       "\n",
       "                                               Clean  \\\n",
       "0  iaaf chief coe says corruption claims abhorren...   \n",
       "1            britaininout goodbyeuk remainineu euref   \n",
       "2  pennsylvania democrats pick establishment s se...   \n",
       "3  last year s runner up johnson in buoyant mood ...   \n",
       "4  theft of construction equipment from wamego bu...   \n",
       "\n",
       "                               Postags   LS   TO  ...   MD   VB  WRB  NNP  \\\n",
       "0  [NN, NN, NN, VBZ, NN, NNS, JJ, NNS]  0.0  0.0  ...  0.0  0.0  0.0  0.0   \n",
       "1                     [IN, JJ, NN, NN]  0.0  0.0  ...  0.0  0.0  0.0  0.0   \n",
       "2       [NN, NNS, VBP, JJ, NN, NN, NN]  0.0  0.0  ...  0.0  0.0  0.0  0.0   \n",
       "3    [JJ, NN, NN, NN, JJ, NN, JJ, NNS]  0.0  0.0  ...  0.0  0.0  0.0  0.0   \n",
       "4    [NN, NN, NN, NN, NN, VBD, NN, NN]  0.0  0.0  ...  0.0  0.0  0.0  0.0   \n",
       "\n",
       "    EX       NNS  SYM   CC   CD  POS  \n",
       "0  0.0  0.250000  0.0  0.0  0.0  0.0  \n",
       "1  0.0  0.000000  0.0  0.0  0.0  0.0  \n",
       "2  0.0  0.142857  0.0  0.0  0.0  0.0  \n",
       "3  0.0  0.125000  0.0  0.0  0.0  0.0  \n",
       "4  0.0  0.000000  0.0  0.0  0.0  0.0  \n",
       "\n",
       "[5 rows x 53 columns]"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "legitmate_data_pos = Clean_legitmate_data.iloc[:,:53]\n",
    "legitmate_data_pos.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "d4768c18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5916, 53)"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full = pd.concat([df_deleted_pos, legitmate_data_pos],sort=False)\n",
    "full.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae9d8377",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
